# 概率统计第十四次作业

## 201300035 方盛俊

## 2.

**(1)**

$\displaystyle E[X]=\int_{-\infty}^{+\infty}xf(x)\mathrm{d}x=\int_{c}^{+\infty}x\cdot \theta c^{\theta}x^{-(\theta+1)}\mathrm{d}x=\theta c^{\theta}\int_{c}^{+\infty}x^{-\theta}\mathrm{d}x=\frac{c\theta}{\theta-1}$

令样本矩等于总体矩 $\bar{X}=E[X]$ 可得

则 $\theta$ 的矩估计量为 $\displaystyle \hat{\theta}=\frac{\bar{X}}{\bar{X}-c}$, 矩估计值为 $\displaystyle \hat{\theta}=\frac{\bar{x}}{\bar{x}-c}$

其中 $\displaystyle \bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}, \bar{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}$

**(2)**

$\displaystyle E[X]=\int_{0}^{1}x\sqrt{\theta}x^{\sqrt{\theta}-1}\mathrm{d}x=\int_{0}^{1}\sqrt{\theta}x^{\sqrt{\theta}}\mathrm{d}x=\frac{\sqrt{\theta}}{\sqrt{\theta}+1}$

则 $\theta$ 的矩估计量为 $\displaystyle \hat{\theta}=\left( \frac{\bar{X}}{\bar{X}-1} \right)^{2}$, 矩估计值为 $\displaystyle \hat{\theta}=\left( \frac{\bar{x}}{\bar{x}-1} \right)^{2}$

**(3)**

$\displaystyle E[X]=\sum_{x=1}^{m}x\cdot \binom{m}{x}p^{x}(1-p)^{m-x}=mp$

则 $p$ 的矩估计量为 $\displaystyle \hat{p}=\frac{\bar{X}}{m}$, 矩估计值为 $\displaystyle \hat{p}=\frac{\bar{x}}{m}$


## 3.

**(1)**

似然函数对数为 $\displaystyle \ln L=\ln \prod_{i=1}^{n}\theta c^{\theta}x_{i}^{-(\theta+1)}=n\ln\theta+\theta n\ln c-(\theta+1)\sum_{i=1}^{n}\ln x_{i}$

对 $\theta$ 求导令其等于零 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}\theta}\ln L=\frac{n}{\theta}+n\ln c-\sum_{i=1}^{n}\ln x_{i}=0$

可得最大似然估计值 $\displaystyle \hat{\theta}=\frac{1}{\frac{1}{n}\sum_{i=1}^{n}\ln x_{i}-\ln c}$

进而最大似然估计量 $\displaystyle \hat{\theta}=\frac{1}{\frac{1}{n}\sum_{i=1}^{n}\ln X_{i}-\ln c}$

**(2)**

似然函数对数为 $\displaystyle \ln L=\ln \prod_{i=1}^{n}\sqrt{\theta}x_{i}^{\sqrt{\theta}-1}=n\ln \sqrt{\theta}+(\sqrt{\theta}-1)\sum_{i=1}^{n}\ln x_{i}$

对 $\sqrt{\theta}$ 求导令其等于零 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}\sqrt{\theta}}\ln L=\frac{n}{\sqrt{\theta}}+\sum_{i=1}^{n}\ln x_{i}=0$

可得最大似然估计值 $\displaystyle \hat{\theta}=\frac{n^{2}}{(\sum_{i=1}^{n}\ln x_{i})^{2}}$

进而最大似然估计量 $\displaystyle \hat{\theta}=\frac{n^{2}}{(\sum_{i=1}^{n}\ln X_{i})^{2}}$

**(3)**

似然函数对数为 $\displaystyle \ln L=\ln \prod_{i=1}^{n}\binom{m}{x_{i}}p^{x_{i}}(1-p)^{m-x_{i}}=\sum_{i=1}^{n}\ln \binom{m}{x_{i}}+\ln p\sum_{i=1}^{n}x_{i}+\ln(1-p)\sum_{i=1}^{n}(m-x_{i})$

对 $p$ 求导令其等于零 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}p}\ln L=\frac{1}{p}\sum_{i=1}^{n}x_{i}+\frac{1}{1-p}(nm-\sum_{i=1}^{n}x_{i})=0$

可得最大似然估计值 $\displaystyle \hat{p}=\frac{\sum_{i=1}^{n}x_{i}}{nm}=\frac{\bar{x}}{m}$

进而最大似然估计量 $\displaystyle \hat{p}=\frac{\sum_{i=1}^{n}x_{i}}{nm}=\frac{\bar{X}}{m}$


## 4.

**(1)**

因为 $\displaystyle E[X]=1\cdot \theta^{2}+2\cdot 2\theta(1-\theta)+3\cdot (1-\theta)^{2}=3 - 2 \theta$

令 $\displaystyle \bar{X}=\frac{1}{3}(1+2+1)=\frac{4}{3}=E[X]=3-2\theta$

可得 $\theta$ 的矩估计值为 $\displaystyle \theta=\frac{3}{2}-\frac{2}{3}=\frac{5}{6}$

最大似然函数对数为 $\displaystyle \ln L=\ln \theta^{2}+\ln 2\theta(1-\theta)+\ln \theta^{2}=5\ln \theta+\ln(1-\theta)+\ln 2$

对 $\theta$ 求导等于零 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}\theta}\ln L=\frac{5}{\theta}-\frac{1}{1-\theta}=0$

可得最大似然估计值 $\displaystyle \hat{\theta}=\frac{5}{6}$

**(2)**

似然函数的对数为 $\displaystyle \ln L=\ln \prod_{i=1}^{n}(\frac{\lambda^{x_{i}}e^{-\lambda}}{x_{i}!})=\ln\lambda\sum_{i=1}^{n}x_{i}-n\lambda-\sum_{i=1}^{n}\ln x_{i}!$

对 $\lambda$ 求导令其等于零 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}\lambda}\ln L=\frac{1}{\lambda}\sum_{i=1}^{n}x_{i}-n=0$

则 $\lambda$ 的最大似然估计量为 $\hat{\lambda}=\bar{X}$

因为 $E[X]=\lambda$, 因此矩估计量也为 $\hat{\lambda}=\bar{X}$

**(3)**

似然函数的对数为 $\displaystyle \ln L=\ln\prod_{i=1}^{n}\binom{x_{i}-1}{r-1}p^{r}(1-p)^{x_{i}-r}=\sum_{i=1}^{n}\ln\binom{x_{i}-1}{r-1}+nr\ln p+(\sum_{i=1}^{n}(x_{i}-r))\ln(1-p)$

对 $p$ 求导令其等于零 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}p}\ln L=\frac{nr}{p}+\frac{nr-\sum_{i=1}^{n}x_{i}}{1-p}=0$

则 $p$ 的最大似然估计值为 $\displaystyle \hat{p}=\frac{r}{\bar{x}}$


## 8.

**(1)**

似然函数的对数为 $\displaystyle \ln L=\ln\prod_{i=1}^{n}\theta x_{i}^{\theta-1}=n\ln\theta+(\theta-1)\sum_{i=1}^{n}\ln x_{i}$

对 $\theta$ 求导等于零得 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}\theta}\ln L=\frac{n}{\theta}+\sum_{i=1}^{n}\ln x_{i}=0$

因此 $\theta$ 的最大似然估计值为 $\displaystyle \hat{\theta}=-\frac{n}{\sum_{i=1}^{n}\ln x_{i}}$

因为 $U=e^{-\frac{1}{\theta}}$ 是单调反函数,

则 $U$ 的最大似然估计值为 $\hat{U}=e^{\frac{\sum_{i=1}^{n}\ln x_{i}}{n}}$

**(2)**

$\mu$ 的最大似然估计值为 $\bar{x}$

而 $\displaystyle \theta=P(X>2)=1-P(X-\mu\leqslant 2-\mu)=1-\Phi(2-\mu)$ 是一个单调函数

因此 $\theta$ 最大似然估计值为 $\hat{\theta}=1-\Phi(2-\bar{x})$

**(3)**

似然函数对数为 $\displaystyle \ln L=\ln \prod_{i=1}^{n}\binom{m}{x_{i}}\theta^{x_{i}}(1-\theta)^{m-x_{i}}=\sum_{i=1}^{n}\ln \binom{m}{x_{i}}+\ln \theta\sum_{i=1}^{n}x_{i}+\ln(1-\theta)\sum_{i=1}^{n}(m-x_{i})$

对 $\theta$ 求导令其等于零 $\displaystyle  \frac{\mathrm{d}}{\mathrm{d}\theta}\ln L=\frac{1}{\theta}\sum_{i=1}^{n}x_{i}+\frac{1}{1-\theta}(nm-\sum_{i=1}^{n}x_{i})=0$

可得 $\theta$ 的最大似然估计值 $\displaystyle \hat{\theta}=\frac{\sum_{i=1}^{n}x_{i}}{nm}=\frac{\bar{x}}{m}$

因为 $\displaystyle \theta=\frac{1}{3}(1+\beta)$ 则 $\beta=3\theta-1$

可得 $\beta$ 的最大似然估计值 $\displaystyle \hat{\beta}=\frac{3\bar{x}}{m}-1$


## 9.

**(1)**

由题目可知 $E[S_1^{2}]=E[S_2^{2}]=\sigma^{2}$, 则有

$
\begin{aligned}
E[S_{w}^{2}]
&=E[\frac{(n_1-1)S_1^{2}+(n_2-1)S_2^{2}}{n_1+n_2-2}] \\
&=\frac{(n_1-1)E[S_1^{2}]+(n_2-1)E[S_2^{2}]}{n_1+n_2-2} \\
&=\sigma^{2} \\
\end{aligned}
$

因此 $S_{w}^{2}$ 是 $\sigma^{2}$ 的无偏估计量.

**(2)**

$\displaystyle E[\frac{\sum_{i=1}^{n}a_{i}X_{i}}{\sum_{i=1}^{n}a_{i}}]=\frac{\sum_{i=1}^{n}a_{i}E[X_{i}]}{\sum_{i=1}^{n}a_{i}}=\frac{\sum_{i=1}^{n}a_{i}\mu}{\sum_{i=1}^{n}a_{i}}=\mu$

因此其是 $\mu$ 的无偏估计量.


## 10.

**(1)**

$
\begin{aligned}
E[c\sum_{i=1}^{n-1}(X_{i+1}-X_{i})^{2}]
&=c\sum_{i=1}^{n-1}(D[X_{i+1}-X_{i}]-(E[X_{i+1}-X_{i}])^{2}) \\
&=c\sum_{i=1}^{n-1}(D[X_{i+1}]+D[X_{i}]) \\
&=2(n-1)c\sigma^{2} \\
\end{aligned}
$

要使得 $\displaystyle E[c\sum_{i=1}^{n-1}(X_{i+1}-X_{i})^{2}]=\sigma^{2}$

因此要 $\displaystyle c=\frac{1}{2(n-1)}$

**(2)**

要使 $\displaystyle E[\bar{X}^{2}-cS^{2}]=E[\bar{X}^{2}]-cE[S^{2}]=(\frac{\sigma^{2}}{n}+\mu^{2})-c\sigma^{2}=\mu^{2}$

则 $\displaystyle c=\frac{1}{n}$


## 11.

**(1)**

似然函数对数为 $\displaystyle \ln L=\ln\prod_{i=1}^{n}\frac{1}{\theta}x_{i}^{\frac{1-\theta}{\theta}}=-n\ln\theta+\frac{1-\theta}{\theta}\sum_{i=1}^{n}\ln x_{i}$

则求导等于零可得 $\displaystyle \frac{\mathrm{d}}{\mathrm{d}\theta}\ln L=-\frac{n}{\theta}-\frac{1}{\theta^{2}}\sum_{i=1}^{n}\ln x_{i}=0$

则最大似然估计量为 $\displaystyle \hat{\theta}=-\frac{1}{n}\sum_{i=1}^{n}\ln X_{i}$

**(2)**

因为 $\displaystyle E[-\ln X]=\int_{0}^{1}(-\ln x)\cdot \frac{1}{\theta}x^{\frac{1-\theta}{\theta}}\mathrm{d}x=-x^{\frac{1}{\theta}}\ln x|_{0}^{1}+\int_{0}^{1}\frac{1}{x}x^{\frac{1}{\theta}}\mathrm{d}x=\theta$

因此 $\displaystyle E[\hat{\theta}]=\frac{1}{n}\sum_{i=1}^{n}E[-\ln X_{i}]=\frac{1}{n}\cdot n\theta=\theta$

因此 $\hat{\theta}$ 是 $\theta$ 的无偏估计.


## 12.

对于均值为 $\theta$ 的指数分布有 $E[X]=\theta, D[X]=\theta^{2}$, 因此

$\displaystyle E[T_1]=\frac{1}{6}(E[X_1]+E[X_2])+\frac{1}{3}(E[X_3]+E[X_4])=\frac{\theta}{3}+\frac{2\theta}{3}=\theta$

$\displaystyle E[T_2]=\frac{1}{5}(E[X_1]+2E[X_2]+3E[X_3]+4E[X_4])=2\theta
$

$\displaystyle E[T_3]=\frac{1}{4}(E[X_1]+E[X_2]+E[X_3]+E[X_4])=\theta$

因此 $T_1, T_3$ 均为 $\theta$ 的无偏估计, 但 $T_2$ 不是.

又因为 $\displaystyle D[T_1]=D[\frac{1}{6}(X_1+X_2)+\frac{1}{3}(X_3+X_4)]=\frac{1}{36}D[X_1]+\frac{1}{36}D[X_2]+\frac{1}{9}D[X_3]+\frac{1}{9}D[X_4]=\frac{5}{18}\theta^{2}$

而 $\displaystyle D[T_3]=\frac{1}{16}(D[X_1]+D[X_2]+D[X_3]+D[X_4])=\frac{1}{4}\theta^{2}$

因此 $T_3$ 比 $T_1$ 有效.


## 13.

**(1)**

因为有 $D[\hat{\theta}]>0$

所以有 $\displaystyle E[\hat{\theta}^{2}]=D[\hat{\theta}]+(E[\theta])^{2}=D[\hat{\theta}]+\theta^{2}>\theta^{2}$

所以 $\hat{\theta}^{2}$ 不是 $\theta^{2}$ 的无偏估计.

**(2)**

因为似然函数 $\displaystyle L(\theta)=\begin{cases} \displaystyle \frac{1}{\theta^{n}}, & 0<x_1,\cdots,x_{n}\leqslant \theta \\ 0, & \text{otherwise} \end{cases}$

可以看出, $L(\theta)$ 随着 $\theta$ 的递增而递减, 所以 $\theta$ 取最小值时有 $L(\theta)$ 最大,

因此 $\displaystyle \hat{\theta}=\max\{x_1,x_2,\cdots,x_{n}\}$

因为总体 $X$ 的分布函数为 $F(x)=\begin{cases} 0, & x<0 \\ \displaystyle \frac{x}{\theta}, & 0\leqslant x\leqslant \theta \\ 1, & x>0 \end{cases}$

因此 $\hat{\theta}=\max\{X_1, X_2, \cdots, X_{n}\}$ 的分布函数为 $F_{\hat{\theta}}(z)=[F(z)]^{n}=\begin{cases} 0, & x<0 \\ \displaystyle (\frac{z}{\theta})^{n}, & 0\leqslant x\leqslant \theta \\ 1, & x>0 \end{cases}$

进而可知 $\hat{\theta}$ 的概率密度为 $\displaystyle f_{\hat{\theta}}(z)=\begin{cases} \displaystyle \frac{n}{\theta}(\frac{z}{\theta})^{n-1}, & 0\leqslant z\leqslant \theta \\ 0, & \text{otherwise} \end{cases}$

于是 $\displaystyle E[\hat{\theta}]=\int_{0}^{\theta}z\cdot \frac{n}{\theta}(\frac{z}{\theta})^{n-1}\mathrm{d}z=\frac{n\theta}{n+1}\neq \theta$

因此 $\hat{\theta}$ 不是 $\theta$ 的无偏估计.


## 14.

由 $E[\bar{X}_{1}]=E[\bar{X}_{2}]=\mu$ 且 $a+b=1$ 可知

$\displaystyle E[Y]=E[a\bar{X}_{1}+b\bar{X}_{2}]=aE[\bar{X}_{1}]+bE[\bar{X}_{2}]=a\mu+b\mu=\mu$

所以 $Y=a\bar{X}_{1}+b\bar{X}_{2}$ 均是 $\mu$ 的无偏估计.

因为 $\displaystyle D[\bar{X}_{1}]=\frac{\sigma^{2}}{n_1}, D[\bar{X}_{2}]=\frac{\sigma^{2}}{n_2}$

所以有 $\displaystyle D[Y]=a^{2}D[\bar{X}_{1}]+b^{2}D[\bar{X}_{2}]=(\frac{a^{2}}{n_1^{2}}+\frac{b^{2}}{n_2^{2}})\sigma^{2}\geqslant \sigma^{2}\cdot 2\sqrt{\frac{a^{2}}{n_1^{2}}\cdot \frac{b^{2}}{n_2^{2}}}=\frac{2ab\sigma^{2}}{n_1n_2}$

当且仅当 $\displaystyle \frac{a^{2}}{n_1^{2}}=\frac{b^{2}}{n_2^{2}}$ 时等号成立.

则 $\displaystyle a=\frac{n_1}{n_1+n_2}, b=\frac{n_2}{n_1+n_2}$ 时, $D[Y]$ 达到最小值 $\displaystyle \frac{2ab\sigma^{2}}{n_1n_2}=\frac{2\sigma^{2}}{(n_1+n_2)^{2}}$




