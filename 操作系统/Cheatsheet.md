# Cheatsheet

## 一、进程和线程

1. 进程和线程的各种状态转换
    1. 新生状态 (new): 表示一个进程刚刚被创建出来, 还未完成初始化, 不能被调度运行. 经过初始化后, 进程进入预备状态. 
    2. 预备状态 (ready): 该状态表示进程可以被调度执行, 但还未被调度器选择. 在被调度器选择执行后, 进程进入运行状态. 
    3. 运行状态 (running): 该状态表示进程正在 CPU 上运行. 当一个进程执行一段时间后, 调度器可以选择中断它并放回调度队列, 进而进入预备状态. 如果进程需要等待一些外部事件, 例如某个 I/O 请求的完成, 就可以放弃 CPU 进入阻塞状态. 当进程运行结束, 它就会进入终止状态. 
    4. 阻塞状态 (blocked): 该状态表示该进程需要等待外部时间, 例如某个 I/O 的完成, 暂时无法被调度. 当该进程等待的外部事件完成后, 就会进入预备状态. 
    5. 终止状态 (terminated): 该状态表示进程已经完成了执行, 且不会再被调度. 
2. 系统调用
    1. 系统调用是一种特殊的异常, 是操作系统为用户程序提供服务的一种手段. 内核实现系统调用是以一个软中断的形式, 即陷阱指令, 如 i386 的 `int 0x80` 指令实现的. 
3. 进程控制块 (PCB)
    1. 在内核中, 每个进程都通过一个数据结构来保存它相关的状态, 如它的进程标识符 PID、进程状态、虚拟内存状态、打开的文件等, 这个数据结构称为进程控制块 PCB. 
4. 多道程序设计
    1. 上下文切换
    2. CPU 利用率: 用于真实计算的 CPU 时间比例
        1. 假设等待 I/O 时间与停留内存时间之比为 $p$, 则 $n$ 个独立进程的 CPU 利用率为 $1-p^{n}$.
5. 线程控制块 (TCB)


## 二、调度

1. 调度的指标
    1. 吞吐: 系统每小时完成的作业数量.
    2. 周转时间: 从一个批处理作业提交时刻开始, 直到该作业完成时刻为止的统计平均时间.
    3. CPU 利用率: CPU 利用率常常用于对批处理系统的度量.
    4. 响应时间: 对于交互式系统来说很重要, 即从发出命令到得到响应之间的时间.
    5. 均衡性: 用户对一件事情需要的时间的固有看法.
    6. 截止时间: 实时系统必须要满足截止时间.
    7. 可预测性: 涉及多媒体的实时系统, 人的耳朵和眼睛十分灵敏, 所以进程调度必须是高度可预测和有规律的.
2. 批处理系统的调度
    1. 先来先服务 (FCFS, FIFO): 当新作业进入, 排到队尾; 当进程被堵塞, 就接着运行队头任务; 当阻塞进程变为就绪时, 进入队尾.
    2. 最短作业优先 (SJF)
    3. 最短剩余时间优先 (SRTN)
3. 交互式系统中的调度
    1. 轮转调度 (RR)
    2. 优先级调度 (PS)
    3. 多级反馈队列 (MLFQ)
        1. 短任务拥有更高的优先级. MLFQ 会为每个任务设置任务的最大运行时间, 如果超过了最大时间, 就会将该任务的优先级减一.
        2. 低优先级的任务采用更长的时间片.
        3. 定时地将所有任务地优先级提升到最高, 保证不会有饥饿.
4. 实时系统的调度
    1. 准入控制: 假设有 $m$ 个任务, 其中第 $i$ 个任务的运行时间记为 $C_i$, 周期记为 $T_i$, 任务在单位时间内对 CPU 的利用率则为 $C_i / T_i$, 则总 CPU 利用率 $U = \sum_{i=1}^{m} C_i / T_i \le 1$.
    2. 单调速率调度 (RM)
        1. 速率指的是任务的到达速率, 它是任务周期的倒数, 即 $1 / T$.
        2. 需要预测任务的周期 $T$, 并且通过周期静态地为每个任务分配一个优先级, 任务的周期越短, 则优先级越高, RM 策略还支持抢占调度, 高优先级任务可以强制低优先级任务执行.
        3. 在所有静态优先级的实时调度策略中, RM 策略是最优的.
        4. RM 策略需要调度 $N$ 个任务时, 最坏情况下的 CPU 利用率为 $N * (2^{1 / N} - 1)$. 两个任务约为 $83\%$, 无限多个任务时约为 $69\%$.
    3. 最早截止期限优先 (EDF)


## 三、内存管理

1. 内存管理: 管理所有和内存相关的操作和保存在主存中的资源, 使得多个进程能够使用主存和资源.
    1. 记录所有被用到的内存;
    2. 动态分配内存;
    3. 权限管理和内存保护;
    4. 回收不需要的内存;
    5. 最大化内存使用率和系统处理能力.
2. 地址空间: 就像进程概念创造了一类抽象的 CPU 以运行程序一样, 地址空间为程序创造了一种抽象的内存. 地址空间时一个进程可用于寻址内存的一套地址集合.每个进程都有一个自己的地址空间, 并且这个地址空间独立于其他进程的地址空间.
3. 动态重定位: 使用基址寄存器和界限寄存器将每个进程的地址空间映射到物理内存的不同部分.
4. 连续内存分配:
    1. 首次适配 (first fit): 沿着链表搜索, 直到找到一个空闲区.
    2. 最佳适配 (best fit): 搜索整个链表, 找出能够容纳进程的最小空闲区.
    3. 最差适配 (worst fit): 总是分配最大的可用空闲区.
    4. 快速适配 (quick fit): 为常用的空闲区维护单独的链表, 类似按照大小对空闲区链表排序, 以便提高最佳适配算法的速度.
5. 内部碎片和外部碎片
    1. 内部碎片: 分页时一个页面过大, 正文段、数据段和堆栈区很可能不会恰好装满整数个页面, 平均的情况下, 最后一个页面有一半是空的, 多余的空间就被浪费掉了, 这种浪费称为内部碎片.
    2. 外部碎片: 与页相比, 段是不定长的, 多次替代和调换后, 就会形成空闲区, 这种现象称为外部碎片. 这种现象可以通过内存紧缩来解决.
6. 虚拟地址: 由程序产生的地址产生的地址称为虚拟地址, 它们共同构成了一个虚拟地址空间. 没开启虚拟内存时, 虚拟地址就是物理地址; 开启了虚拟内存时, 虚拟地址不是直接被送到内存总线, 而是被送到内存管理单元 (MMU), 由 MMU 负责把虚拟地址映射为物理内存地址.
7. 分页
    1. 页框: 虚拟地址空间按照固定大小划分为被称为页面的若干单元, 在物理内存中对应的单元称为页框.
    2. 页表项: 不同计算机的页表项大小可能不一样, 但是 32 位是一个常用的大小. 常包括页框号、保护位、修改位 (脏位)、访问位和禁用高速缓存位. 修改位和访问位对页置换算法很有用, 禁用高速缓存位对内存映射 I/O 很有用.
    3. 转换检测缓冲区/快表 (TLB): 通常在 MMU 中, 包含少量的表项, 一般不会超过 256 个, 每个表项包括有效位、虚拟页面号、修改位、保护位和页框号. 工作时, 硬件将虚拟页号与 TLB 中所有表项并行比较并匹配, 如果发现了有效的表项, 则就不用访问页表. 如果 MMU 检测到没有有效匹配项, 则会查找页表, 然后从 TLB 中淘汰一个表项.
    4. 多级页表: 32 位的虚拟地址常常被分为 10 位的 PT1 域、10 位的 PT2 域和 12 位的偏移量, 这样能够解决页表过大的问题.
    5. 倒排页表: 内存中的每个页框对应一个表项, 而不是每个虚拟页面对应一个表项. 但是这样会导致虚拟地址到物理地址会很困难, 解决这种困难的方法是 TLB 和散列表.
    6. 请求调页: 当应用程序申请分配内存时, 操作系统可以选择将新分配的虚拟页标记为已分配但未映射到物理内存的状态, 而不必为这个虚拟页分配对应的物理页. 当应用程序访问这个虚拟页的时候, 会触发缺页异常, 这时候才真正为其分配物理页.
    7. 缺页异常
        1. 硬件陷入内核, 在堆栈中保存 PC.
        2. 启动一个汇编代码历程保存通用寄存器和其他易失信息.
        3. 发现缺页中断, 尝试就找需要哪个虚拟页.
        4. 检查虚拟页地址是否有效, 然后检查是否有空闲页框, 如果没有, 则执行页面置换算法来找一个页面来淘汰.
        5. 如果选择的页框是脏的, 则安排该页写回磁盘, 并由于 I/O 操作而发生一次进程调度.
        6. 一旦页框干净, 则查找所需页面在磁盘上的地址, 通过 I/O 操作装入内存, 同样发生进程调度.
        7. 磁盘中断发生时, 表示该页已经载入, 页表也可以更新, 以反映它的位置.
        8. 恢复发生缺页中断以前的状态, PC 重新指向这条指令.
        9. 调度引发缺页中断的进程.
        10. 恢复寄存器和其他状态信息, 返回用户空间继续执行.
    8. 页面置换算法
        1. 最优 (Optimal): 通过模拟执行代码以了解所有页面的使用顺序, 总是替换掉最晚将被使用的页面.
        2. 最近未使用 (NRU): 读位 R 定时被置 0, 并且有一个写位 W, 然后根据 RW 将页面分为 00 到 11 这四类, 然后随机地从类编号最小地非空类中挑选一个页面淘汰.
        3. 先进先出 (FIFO): 最早被载入的页面最早被淘汰.
        4. 二次机会: 检查最老页面的 R 位, 如果 R 位是 0, 则立刻置换掉; 如果 R 位是 1, 则清零, 然后放到链表尾端, 就好像刚装入一样, 然后继续搜索.
        5. 时钟算法: 用循环链表来实现二次机会中的链表, 以减少将页面放入链表尾端的时间.
        6. 最近最少用 (LRU): 置换未使用时间最长的页面. 一个简单的实现方式是硬件有一个计算已经执行了多少条指令的计数器 C, 每次访问内存后, 将当前的 C 值保存到当前页面对应页表项中. 一旦发生缺页中断, 就淘汰掉值最小的一个页面.
        7. 最不常用 (NFU): 一种模拟 LRU 的算法, 将每一个页面与一个软件计数器相关联, 计数器初值为 0. 每次时钟中断时, 将页面的 R 值加到计数器中. 然而, 要加入老化机制, 在 R 位被加入前, 先将计数器右移一位, 然后将 R 位加到计数器最左端的位, 而不是最右端的位. 发生缺页中断时, 将置换计数器最小的页面.
    9. 工作集
        1. 工作集: 一个进程当前正在使用的页面的集合称为它的工作集. 它是随着时间变化而发生变化的. 定义上, 工作集就是最近 $k$ 次内存访问所使用过的页面的集合.
        2. 颠簸: 如果每执行几条指令程序就发生一次缺页中断, 那么就称这个程序发生了颠簸.
        3. 访问局部性: 在进程运行的任何阶段, 它都只访问较少的一部分页面.
        4. 工作集置换算法: 当发生页中断时, 淘汰一个不在工作集中的页面.


## 四、同步

1. 竞争条件: 两个或多个进程读写某些共享数据, 而最后的结果取决于进程运行的精确时序, 称为竞争条件.
2. 临界区: 我们把共享内存进行访问时的程序片段称作临界区.
    1. 安全性: 任何两个进程不能同时处于其临界区.
    2. 不应该对 CPU 速度和数量做任何假设.
    3. 临界区外运行的进程不得阻塞其他进程.
    4. 活性: 不得使进程无期限等待进入临界区.
3. 互斥
    1. 忙等待: 连续测试一个变量直到某个值出现为止, 称为忙等待. 用于忙等待的锁, 称为自旋锁.
    2. 皮特森算法: 只需要两个全局变量 `turn` 和 `interested` 来分别指示轮到的进程 (其实感觉更应该说是轮到谁等待) 和对临界区感兴趣的进程.
        ```c
        void enter_region(int process) {
            int other = 1 - process;
            interested[process] = TRUE;
            turn = process;
            while (turn == process && interested[other] == TRUE);
        }

        void leave_region(int process) {
            interested[process] = FALSE;
        }
        ```
    3. TSL 指令: 测试并加锁, `TSL RX, LOCK` 可以原子地将 `LOCK` 读到 `RX` 寄存器中, 并在 `LOCK` 处写一个非零值. 类似地还有原子地交换两个位置内容的指令 XCHG.
    4. 优先级反转: 由于低优先级进程 L 占据了临界区, 导致高优先级进程 H 一直在临界区外忙等待, 让 L 不能被调度, 也就不能出临界区. 这种情况有时候称为优先级反转. 
4. 条件变量
    1. 生产者消费者问题:
        ```c
        pthread_mutex_lock(&mutex);
        while (buffer ?= 0) pthread_cond_wait(&cond, &mutex);
        buffer = ?;
        pthread_cond_signal(&cond);
        pthread_mutex_unlock(&mutex);
        ```
5. 信号量
    1. P (down): 对一个信号量尝试减 1, 如果等于零 0, 则无法减 1, 只能将进程睡眠, 此时 down 操作仍未结束, 会等待有一个进程加 1 后继续.
    2. V (up): 对一个信号量加 1, 如果有进程在这个信号量上睡眠, 则会随机唤醒一个进程让其继续 down 操作.
    3. 通过信号量实现互斥锁和条件变量: 设定信号量初值为 `1` 即可实现加锁; 设定信号量初值为 `0` 即可实现条件变量.
    4. 通过互斥锁和条件变量实现信号量:
        ```c
        void P(semaphore *s) {
            mutex_lock(&(s->mutex));
            while (s->val == 0) {
                wait(&(s->cond), &(s->mutex));
            }
            s->val--;
            mutex_unlock(&(s->mutex));
        }
        void V(semaphore *s) {
            mutex_lock(&(s->mutex));
            s->val++;
            signal(&(s->cond));
            mutex_unlock(&(s->mutex));
        }
        ```
    5. 生产者消费者问题: 使用 `full`, `empty` 和 `mutex` 三个信号量来解决. `full` 初值为 0, `empty` 初值为缓冲区中槽数量, `mutex` 初值为 1.
        ```c
        // producer
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
        // consumer is similar
        ```
6. 管程
    1. 定义: 一个管程是一个由过程、变量以及数据结构等组成的一个集合, 且任一时刻管程中只能有一个活跃进程. (可以简单理解为由编译器管理的互斥量或二元信号量).
    2. 自身阻塞: 引入条件变量和两个相关操作 `wait` 和 `signal`. 而 `signal` 后对进程的处理, 则引出了三种不同的语义.
    3. Hoare: 让新唤醒进程运行, 挂起发信号进程. 因此需要三个队列 `signal_queue`, `wait_queue` 和 `ready_queue`, 因此是实现起来最复杂的.
    4. Hansen: 执行 `signal` 的进程必须立刻退出管程, 即 `signal` 是管程的最后一条语句. 因为 Hansen 语义为简单, 只需要 `wait_queue` 和 `ready_queue`.
    5. Mesa: 让发信号进程继续运行, 直到发信号进程退出管程后, 才允许等待的进程开始运行. 类似 Hansen 语义, 只不过没有了 `signal` 是末尾语句的限制, 也只需要 `wait_queue` 和 `ready_queue`, 因此被广泛地实现. 但是因此也要注意一个问题, 线程被唤醒时, 必须检查 `condition` 是否满足, 也就是要使用 `while` 而不是 `if`.
7. 生产者消费者问题: 同上
8. 读者写者问题
    1. 读写锁: 多个读者可以同时进入临界区; 但是如果有一个写者在临界区内, 则必须保证临界区内没有其他读者和写者.
    2. 偏向问题: 在某一时刻, 已经有一些读者在临界区中. 此时有一个写者和一个读者同时申请进入临界区, 那么应该先让写者进入还是读者进入临界区. 优先读者可能导致写者饿死, 优先写者可能会减少读者并行性而减少效率. 我们也可以使用一个队列来依次服务, 这时则称为相对公平.
    3. 读者偏向: 实现起来比较简单, 只需要使用两个锁 `reader_lock` 和 `writer_lock`, 维持一个读者计数 `reader_cnt`, 并且在第一个读者进入时锁上写者锁, 在最后一个读者退出时解锁写者锁即可.
    4. 写者偏向: 相对复杂, 需要 `reader_cnt`, `has_writer`, `lock`, `reader_cond` 和 `writer_cond`. 读者需要根据 `has_writer` 来使用 `writer_cond` 阻塞自身, 写者需要在仍有读者时用 `reader_cond` 来阻塞自身.
    5. 相对公平: 更加复杂了, 通过信号量 `Line` 来保持 FIFO 队列的唤醒顺序, 并且使用各种各样的变量来实现同步, 这里就省略吧, 反正也记不住.
9.  Read-Copy-Update (RCU)
    1. RCU 主要针对的数据对象是链表, 目的是提高遍历读取数据的效率, 为了达到目的使用 RCU 机制读取数据的时候不对链表进行耗时的加锁操作. 这样在同一时间可以有多个线程同时读取该链表, 并且允许一个线程对链表进行修改 (修改的时候, 需要加锁).
    2. 保证读取链表的完整性. 新增或者删除一个节点, 不至于导致遍历一个链表从中间断开. 但是 RCU 并不保证一定能读到新增的节点或者不读到要被删除的节点. 
    3. 订阅-发布机制: 在读取过程中, 另外一个线程插入了一个新节点, 而读线程读到了这个节点, 那么需要保证读到的这个节点是完整的. 这里涉及到了发布-订阅机制 (Publish-Subscribe Mechanism).
        ```c
        // 发布
        rcu_assign_pointer(&NodeA->Next, NodeC);
        // 订阅
        read = rcu_dereference(&Node->Next);
        ```
    4. 宽限期: 在读取过程中, 另外一个线程删除了一个节点. 删除线程可以把这个节点从链表中移除, 但它不能直接销毁这个节点, 必须等到所有的读取线程读取完成以后, 才进行销毁操作. RCU 中把这个过程称为宽限期(Grace period).
        ```c
        // 用来保持一个读者的 RCU 临界区
        rcu_read_lock()
        rcu_read_unlock()

        // RCU 的核心所在, 它挂起写线程, 等待读者都退出后释放老的数据
        synchronize_rcu()
        ```
10. 哲学家就餐问题
    1. 死锁: 同时拿起左叉, 但是不放下, 就会导致死锁.
    2. 饿死: 同时拿起左叉, 同时放下, 同时又拿起右叉, 同时又放下, 循环进行, 就会导致饿死.
    3. 最简单的解决方法: 破除依赖, 让一个哲学家与众不同, 他先拿右叉, 而不是像其他人那样拿起左叉.
    4. 一个相对复杂的解决方法:
        ```c
        void take_forks(int i) {
            down(&mutex);
            state[i] = HUNGRY;
            test(i);
            up(&mutex);
            down(&s[i]);  // 可能阻塞, 等待邻居主动递叉子
        }
        void put_forks(int i) {
            down(&mutex);
            state[i] = THINKING;
            test(LEFT);
            test(RIGHT);
            up(&mutex);
        }
        void test(i) {
            if (state[i] == HUNGRY &&
                state[LEFT] != EATING && state[RIGHT] != EATING) {
                state[i] = EATING;
                up(&s[i]);  // 拿到叉子了, 解除阻塞
            }
        }
        ```


## 五、死锁

1. 死锁四个必要条件
    1. 互斥: 每个资源要么分配给了一个进程, 要么是可用的.
    2. 持有并等待: 已经得到了某个资源的进程可以再次申请新资源.
    3. 不可抢占: 已经分配给一个进程的资源不能强制性地被抢占.
    4. 环路等待: 死锁发生时, 一定有两个或两个以上的进程组成了一条环路, 环路中的每个进程都在等待下一个进程占有的资源.
2. 资源分配图
    1. 每种类型一个资源: 用圆形表示进程, 用方形表示资源. 从资源到进程的箭头代表进程占有一个资源; 从进程到资源的箭头代表进程请求一个资源.
    2. 每种类型多个资源: $E$ 代表现有资源向量, 即每种已存在的资源的总数; $A$ 是可用资源向量, 即当前剩余的每种资源的数量; $C$ 代表当前分配矩阵; $R$ 代表请求矩阵. 则我们有 $\sum_{i=1}^{n}C_{ij} + A_{j} = E_{j}$.
3. 死锁检测
    1. 每种类型一个资源: 用环路检测算法, 即 DFS, 依次将每一个节点作为一棵树的根节点, 进行深度优先搜索.
    2. 每种类型多个资源: 基于资源分配矩阵, 请求矩阵和可用向量的算法检测. (和银行家算法基本就是一模一样?)
        1. 寻找一个没有标记的进程 $P_{i}$, 对于它而言 $R_{i} \le A$.
        2. 如果找到了 $P_{i}$, 则将 $C_{i}$ 加到 $A$ 中, 标记该进程, 转到第 1 步.
        3. 如果没找到 $P_{i}$, 则算法终止. 所有没有标记过的进程都是死锁进程.
4. 死锁避免
    1. 安全状态: 存在一个分配序列使得所有的进程都能完成.
    2. 不安全状态: 不存在一个分配序列使得所有的进程都能完成. 理论上来说不安全状态不是死锁, 因为依然有进程能运行一段时间. 但是实际上应该说有部分程序有死锁, 而另一部分程序没有死锁.
    3. 银行家算法: 对每一个请求进行检查, 检查如果满足这一请求是否会达到安全状态. 若是, 则满足该请求; 若不是, 则推迟对这一请求的满足.
        1. 寻找一个没有标记的进程 $P_{i}$, 对于它而言 $R_{i} \le A$.
        2. 如果找到了 $P_{i}$, 则将 $C_{i}$ 加到 $A$ 中, 标记该进程, 转到第 1 步.
        3. 如果没找到 $P_{i}$, 则算法终止. 如果所有进程都被标记过, 也就是没有死锁, 则这个状态是安全的.
5. 死锁预防: 破坏四个条件中随便一个.


## 六、文件系统

1. 文件系统的功能
2. 文件
    1. 文件的命名和属性
    2. 文件的顺序和随机访问模式
    3. 与文件相关的操作
    4. inode
    5. 打开文件表 (Open-File Table)
3. 目录
    1. 目录的层级结构
    2. 硬链接和符号链接
4. 文件和目录的角色: 两个关键的抽象.
5. 文件系统布局
6. 文件存储的实现
    1. Contiguous
    2. Linked List
    3. FAT
    4. Indexed (inode 多级索引)
7. 目录的实现
    1. 目录项中包含的信息
    2. 不同长度文件名的处理
    3. 在目录中查找文件
8. 磁盘空闲空间管理
    1. 不同数据块大小对文件系统的影响
    2. 记录空闲块
        1. Bit Map
        2. Free List
9. 文件系统的性能
    1. 缓存
    2. 快速文件系统
10. 文件系统一致性
    1. 文件系统一致性检查 (fsck)
    2. 日志文件系统
11. 虚拟文件系统


## 七、设备管理

1. 设备控制器
2. 设备类型
    1. 块设备
    2. 字符设备
3. 设备驱动程序
4. 端口映射 I/O
5. 内存映射 I/O
6. 直接存储器存取 (DMA)
7. 廉价磁盘冗余阵列
8. 磁盘臂调度算法
    1. 电梯算法

